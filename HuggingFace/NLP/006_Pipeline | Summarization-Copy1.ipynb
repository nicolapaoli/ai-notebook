{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7cb0179-40c0-48b3-a112-0dca7d5821ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following NLP Course here:\n",
    "# https://huggingface.co/learn/nlp-course/chapter1/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acf6a69a-40a2-4044-9352-ef17910d94cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d80f1e14-ebe5-4d68-ab13-777773493479",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae210250a9e40518060688e762e434d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdcf6d5efbbd41e7b6b15a50edb516e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6294e925a144fbb1904ad1483d0fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af06029d9dd4c3a90471d09422776a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2a34ad10e7144ad88faccc7360ead95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pipeline for summarization\n",
    "summarizer = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de3902d5-d71e-4055-9a43-34261f4d2061",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 142, but your input_length is only 77. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=38)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': \" This is just an example of a big text to pass to the pipeline . After that, this function will be able to summarize the text . Then you can use a shorter version of it . Basically that's just the goal of summarization. I can stop writing now.\"}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(\"Blah blah blah..generating a lot of context here. This is just an example of a big text to pass to the pipeline. After that, this function will be able to summarize the text. Then you can use a shorter version of it. Basically that's just the goal of summarization. I can stop writing now. Hopefully. Please summarize it for me.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14b13381-fbba-403d-9085-31dcd9e4cba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your min_length=56 must be inferior than your max_length=20.\n",
      "/usr/local/lib/python3.10/site-packages/transformers/generation/utils.py:1285: UserWarning: Unfeasible length constraints: `min_length` (56) is larger than the maximum possible length (20). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' This is just an example of a big text to pass to the pipeline . After that'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(\n",
    "    \"Blah blah blah..generating a lot of context here. This is just an example of a big text to pass to the pipeline. After that, this function will be able to summarize the text. Then you can use a shorter version of it. Basically that's just the goal of summarization. I can stop writing now. Hopefully. Please summarize it for me.\",\n",
    "    max_length=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb39d33e-6f64-4918-b384-ee858107f0d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
